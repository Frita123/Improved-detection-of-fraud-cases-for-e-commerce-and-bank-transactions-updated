# Improved-detection-of-fraud-cases-for-e-commerce-and-bank-transactions-updated# ğŸ›¡ï¸ Improved Detection of Fraud Cases for E-Commerce and Bank Transactions

This project focuses on building robust machine learning models to detect fraudulent transactions using two datasets:

- E-commerce fraud dataset  
- Credit card transaction dataset  

The pipeline includes feature engineering, model training, evaluation, explainability (SHAP), and preparation for deployment via a Streamlit dashboard.

---

## ğŸ“Œ Project Objectives

- Detect fraudulent transactions with high accuracy
- Compare performance across two datasets
- Provide model explainability using SHAP
- Visualize results via ROC curves and feature importance
- Prepare for real-time inference using a Streamlit dashboard

---

## âœ… Completed Tasks

### Task 1 â€” Data Preparation & Feature Engineering

âœ” Cleaned raw datasets  
âœ” Handled missing values  
âœ” Encoded categorical variables  
âœ” Scaled numerical features  
âœ” Generated engineered features  
âœ” Split into train/test sets  

Processed files are stored in:

data/processed/


---

### Task 2 â€” Model Training

Random Forest classifiers were trained separately for:

- Fraud Dataset  
- Credit Card Dataset  

Saved artifacts:

- Trained models (`.pkl`)
- Feature scalers

These are excluded from Git via `.gitignore`.

---

### Task 3 â€” Model Evaluation

Metrics computed:

- ROC Curve
- AUC Score
- Feature importance (Random Forest)

Visualizations:

âœ” ROC curves for both datasets  
âœ” Top 15 RF feature importance plots  

---

### Task 4 â€” Model Explainability (SHAP)

Implemented SHAP for both models:

âœ” Beeswarm plots  
âœ” SHAP bar charts  
âœ” Mean absolute SHAP values  
âœ” Combined feature comparison tables  

Key outputs:

- SHAP summary plots  
- Feature importance rankings  
- CSV comparison tables  

All SHAP artifacts are saved locally and ignored by Git.

---

## ğŸ“Š Explainability Outputs

Generated:

- SHAP beeswarm plots  
- SHAP bar charts  
- Combined comparison table:

notebooks/shap_outputs/


---

## ğŸ“ Project Structure

Improved-detection-of-fraud-cases/

â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/
â”‚ â””â”€â”€ processed/
â”‚
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ shap.ipynb
â”‚ â””â”€â”€ shap_outputs/ (ignored by git)
â”‚
â”œâ”€â”€ models/ (ignored by git)
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ data_loader.py
â”‚ â”œâ”€â”€ feature_engineering.py
â”‚ â””â”€â”€ train.py
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md


---

## âš™ï¸ How to Run

### 1. Create virtual environment

```bash
python -m venv .venv
.venv\Scripts\activate
2. Install dependencies
pip install -r requirements.txt
3. Run SHAP explainability
Open:

notebooks/shap.ipynb
Run all cells.

ğŸ“ˆ Models Used
Random Forest Classifier (Fraud)

Random Forest Classifier (Credit Card)

ğŸ” Git Management
Ignored files:

.pkl

SHAP plots

SHAP CSV outputs

Virtual environment

Handled via .gitignore.

ğŸš€ Next Steps
ğŸ”¹ Task 5 â€” Streamlit Dashboard (Upcoming)
Build an interactive dashboard with:

âœ… File upload / manual input
âœ… Fraud probability prediction
âœ… SHAP explanation per transaction
âœ… Feature importance visualization
âœ… ROC curve display

Planned features:

Sidebar controls

Dataset selector

Real-time prediction

Explainability panel

ğŸ”¹ Task 6 â€” Testing
Implement:

Unit tests for preprocessing

Model prediction tests

Input validation

Edge-case testing

Using:

pytest

ğŸ¯ Future Improvements
Hyperparameter tuning

Model comparison (XGBoost / LightGBM)

Real-time API deployment

Dockerization

Cloud hosting

ğŸ‘©â€ğŸ’» Author
Firehiwet Zerihun


